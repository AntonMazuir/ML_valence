import sys
import os
from pathlib import Path
from datetime import datetime

# On s'assure que le dossier racine est dans le path pour les imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from ingestion import IdealistaClient
from processing import DataProcessor
from model import ValenceModel
from scan import detect_opportunities, print_report
from dashboard import generate_html_dashboard

def run_pipeline():
    print("ğŸš€ DÃ‰MARRAGE DU PIPELINE INVEST VALENCE V5 - ROBUSTE\n")

    # --- Ã‰TAPE 0 : PRÃ‰PARATION ---
    # CrÃ©ation des dossiers nÃ©cessaires s'ils manquent pour Ã©viter les erreurs d'Ã©criture
    for folder in ['data/raw', 'data/processed', 'models']:
        os.makedirs(folder, exist_ok=True)

    # --- Ã‰TAPE 1 : INGESTION (Optionnelle) ---
    print("--- ğŸ“¡ Ã‰TAPE 1 : RÃ‰CUPÃ‰RATION DES DONNÃ‰ES ---")
    # Note : Ingestion sautÃ©e pour prÃ©server les crÃ©dits API (on travaille sur l'historique)
    print("âœ… Utilisation des donnÃ©es JSON existantes dans data/raw/.\n")

    # --- Ã‰TAPE 2 : DATA PROCESSING (L'intelligence de ton pÃ¨re & NLP) ---
    print("--- ğŸ§¹ Ã‰TAPE 2 : NETTOYAGE, TRAVAUX ET RENDEMENTS ---")
    processor = DataProcessor()
    raw_df = processor.load_all_json()

    if not raw_df.empty:
        # Cette Ã©tape calcule : Travaux (1500â‚¬/m2), Frais, Loyers, Airbnb et Clusters
        clean_df = processor.clean_for_ml(raw_df)
        processor.save_processed(clean_df)
        print(f"âœ… {len(clean_df)} annonces filtrÃ©es et enrichies financiÃ¨rement.\n")
    else:
        print("âŒ Erreur : Aucun fichier JSON trouvÃ© dans data/raw/.")
        return

    # --- Ã‰TAPE 3 : TRAINING IA (Estimation de Valeur de MarchÃ©) ---
    print("--- ğŸ§  Ã‰TAPE 3 : ENTRAÃNEMENT DE L'IA (MODE ROBUSTE) ---")
    ai = ValenceModel()
    # L'IA apprend Ã  estimer le prix SANS regarder les variables financiÃ¨res (Anti-Triche)
    ai.train()
    print("âœ… ModÃ¨le V5 (Depth 4) mis Ã  jour et sauvegardÃ©.\n")

    # --- Ã‰TAPE 4 : SCANNER LE MARCHÃ‰ (DÃ©tection des pÃ©pites) ---
    print("--- ğŸ¯ Ã‰TAPE 4 : DÃ‰TECTION DES OPPORTUNITÃ‰S ---")
    # On utilise le score composite : Marge + Yield + Momentum + Bonus Confort
    opportunities = detect_opportunities(data_path='data/processed/valence_training_set.csv')

    if not opportunities.empty:
        # Affichage du Top 15 dans le terminal pour un check rapide
        print_report(opportunities)

        # Sauvegarde d'archive CSV avec la date du jour
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        output_file = f'data/opps_valence_{timestamp}.csv'
        opportunities.to_csv(output_file, index=False)
        print(f"âœ… Archive CSV sauvegardÃ©e : {output_file}")

        # --- Ã‰TAPE 5 : GÃ‰NÃ‰RATION DU DASHBOARD VISUEL ---
        print("\n--- ğŸ“Š Ã‰TAPE 5 : GÃ‰NÃ‰RATION DU DASHBOARD HTML ---")
        # CrÃ©ation de la page web interactive avec photos et badges
        generate_html_dashboard(opportunities)
        print("âœ… Dashboard HTML mis Ã  jour (dashboard.html). PrÃªt pour l'analyse !\n")

    else:
        print("â„¹ï¸ Aucune opportunitÃ© ne correspond aux critÃ¨res de sÃ©curitÃ© (Marge 10-50%).")

    print("ğŸ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS ! Tu peux ouvrir dashboard.html.")

if __name__ == "__main__":
    run_pipeline()
